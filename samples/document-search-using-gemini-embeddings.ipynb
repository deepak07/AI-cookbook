{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Quadrant client and create collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install qdrant-client\n",
    "%pip install dotenv\n",
    "%pip install PyPDF2\n",
    "%pip install langchain\n",
    "%pip install google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "QDRANT_HOST_URL = os.getenv('QDRANT_HOST_URL')\n",
    "COLLECTION_NAME = \"documents-collection\"\n",
    "EMBEDDING_MODEL = \"text-embedding-004\"\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "  url=QDRANT_HOST_URL\n",
    ")\n",
    "\n",
    "if not qdrant_client.collection_exists(COLLECTION_NAME):\n",
    "  qdrant_client.create_collection(\n",
    "      collection_name=COLLECTION_NAME,\n",
    "      vectors_config=models.VectorParams(\n",
    "        size=768,\n",
    "        distance=models.Distance.COSINE\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a PDF file and convert those to chunks of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "pdf = \"assets/StockMarketAnalysis.pdf\"\n",
    "text = \"\"\n",
    "\n",
    "with open(pdf,'rb') as file:\n",
    "    pdf_reader = PdfReader(file)\n",
    "\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "      )\n",
    "chunks = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert chunks into points vector by sending to open AI and store those to Qdrant collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting chunks into points which are central entity of Qdrant\n",
    "# and putting them up on vector store\n",
    "\n",
    "import uuid\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "points = []\n",
    "google_ai_client = genai.Client()\n",
    "\n",
    "print(len(chunks), \"chunks to embed\")\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "  print(\"Embedding chunk\", idx+1, \"/\", len(chunks))\n",
    "  response = google_ai_client.models.embed_content(\n",
    "    contents=chunk,\n",
    "    model=EMBEDDING_MODEL,\n",
    "    config=types.EmbedContentConfig(output_dimensionality=768)\n",
    "  )\n",
    "  embeddings = response.embeddings[0].values\n",
    "  point_id = str(uuid.uuid4())  # Generate a unique ID for the point\n",
    "  points.append(PointStruct(\n",
    "    id=point_id,\n",
    "    payload={\"text\": chunk},\n",
    "    vector=embeddings\n",
    "    )\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Upserting\", len(points), \"points\")\n",
    "qdrant_client.upsert(\n",
    "  collection_name=COLLECTION_NAME,\n",
    "  wait=True,\n",
    "  points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a query to OpenAI to vecorize and search that in Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is a candlistick chart?\"\n",
    "\n",
    "response = google_ai_client.models.embed_content(\n",
    "  contents=query,\n",
    "  model=EMBEDDING_MODEL,\n",
    "  config=types.EmbedContentConfig(output_dimensionality=768)\n",
    ")\n",
    "\n",
    "embeddings = response.embeddings[0].values\n",
    "search_result = qdrant_client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=embeddings,\n",
    "    limit=3\n",
    ").points\n",
    "\n",
    "prompt=\"\"\n",
    "for result in search_result:\n",
    "    prompt += result.payload['text']\n",
    "concatenated_string = \" \".join([prompt,query])\n",
    "completion = google_ai_client.models.generate_content(\n",
    "  model='gemini-2.0-flash',\n",
    "  contents= concatenated_string\n",
    ")\n",
    "\n",
    "print(completion.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
