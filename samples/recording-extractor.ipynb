{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependency for ffmpeg\n",
    "brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'transformers[torch]'\n",
    "%pip install datasets\n",
    "%pip install librosa soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepak/my-space/ai-cookbook/ai-cookbook/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n",
      "/Users/deepak/my-space/ai-cookbook/ai-cookbook/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" But the best way to start a speech and the way that I hope all of you use from now forward is the same way we start a story to a child. How do we start a story to a child? Erase una vez. Once upon a time. And what happens when you say once upon a time? I can tell you what happens when I say, once upon a time, my daughter leans forward, gets ready to hear, engages. And we were all trained as kids to know when a story is coming. We also know when a teacher is about to deliver a 40-minute boring lecture that has no impact on our lives. But in business, you don't hear Jack Welch saying, once upon a time. Steve Jobs doesn't hot-start his speeches once upon a time so there's a grown-up way of saying once upon a time and if you listen to the conversations that are interesting around you at a dinner table and networking event if you listen to the people that are gathering the group of eight that are listening to them the way they're talking is different the way they start is different. The way you tell stories as an adult is in October was the last time I was in this room. There were 120 people in the room having a little conversation with one of the world experts on public speaking and he said something to me. He said something to me has had me thinking ever since. He said something to me that changed what I think about what's important in speaking. Now I can pause for about 30 seconds, two, three minutes, and you'll want to know what he said. So in speaking in sales, we assume self-interest. So if you can tell a story from your own life that connects you to why this topic is important to you, why you first joined the company, when you first saw someone benefit.\", 'chunks': [{'timestamp': (0.0, 8.36), 'text': ' But the best way to start a speech and the way that I hope all of you use from now forward'}, {'timestamp': (8.36, 15.12), 'text': ' is the same way we start a story to a child.'}, {'timestamp': (16.92, 19.72), 'text': ' How do we start a story to a child?'}, {'timestamp': (22.12, 23.5), 'text': ' Erase una vez.'}, {'timestamp': (24.26, 25.9), 'text': ' Once upon a time.'}, {'timestamp': (25.9, 29.7), 'text': ' And what happens when you say once upon a time?'}, {'timestamp': (0.0, 8.84), 'text': ' I can tell you what happens when I say, once upon a time, my daughter leans forward, gets ready to hear, engages.'}, {'timestamp': (10.92, 15.88), 'text': ' And we were all trained as kids to know when a story is coming.'}, {'timestamp': (17.66, 23.9), 'text': ' We also know when a teacher is about to deliver a 40-minute boring lecture that has no impact on our lives.'}, {'timestamp': (25.24, 29.76), 'text': \" But in business, you don't hear Jack Welch saying, once upon a time.\"}, {'timestamp': (0.0, 4.66), 'text': \" Steve Jobs doesn't hot-start his speeches once upon a time so there's a\"}, {'timestamp': (4.66, 11.24), 'text': ' grown-up way of saying once upon a time and if you listen to the conversations'}, {'timestamp': (11.24, 16.36), 'text': ' that are interesting around you at a dinner table and networking event if you'}, {'timestamp': (16.36, 19.18), 'text': ' listen to the people that are gathering the group of eight that are listening to'}, {'timestamp': (19.18, 23.48), 'text': \" them the way they're talking is different the way they start is\"}, {'timestamp': (23.48, 0.0), 'text': ''}, {'timestamp': (10.06, 14.16), 'text': ' different. The way you tell stories as an adult is in October was the last time I was in this room. There were 120 people in the room having a little conversation'}, {'timestamp': (14.16, 20.78), 'text': ' with one of the world experts on public speaking and he said something to me. He'}, {'timestamp': (20.78, 26.96), 'text': ' said something to me has had me thinking ever since. He said something to me that'}, {'timestamp': (26.96, 0.0), 'text': ''}, {'timestamp': (4.72, 9.04), 'text': \" changed what I think about what's important in speaking.\"}, {'timestamp': (14.96, 15.3), 'text': \" Now I can pause for about 30 seconds, two, three minutes, and you'll want to know what he said.\"}, {'timestamp': (18.9, 26.24), 'text': ' So in speaking in sales, we assume self-interest.'}, {'timestamp': (27.5, 0.0), 'text': ''}, {'timestamp': (7.14, 13.26), 'text': ' So if you can tell a story from your own life that connects you to why this topic is important to you, why you first joined the company, when you first saw someone benefit.'}]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps=True\n",
    ")\n",
    "\n",
    "result = pipe('./assets/my-recordings.flac')\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
